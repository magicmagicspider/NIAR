import asyncio
import json
import logging
import fcntl
import os
from datetime import datetime
from typing import Optional

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from croniter import croniter
from sqlmodel import Session

from app.models.db import engine
from app.models.scheduled_task import ScheduledTask
from app.models.task_execution import TaskExecution
from app.repositories.scheduled_task_repo import ScheduledTaskRepository
from app.repositories.task_execution_repo import TaskExecutionRepository
from app.repositories.app_config_repo import AppConfigRepository
from app.services.scan_service import scan_nmap, upsert_devices_with_info
from app.services.bettercap_service import BettercapClientManager
from app.repositories.system_event_log_repo import SystemEventLogRepository

logger = logging.getLogger(__name__)

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
_scheduler: Optional[BackgroundScheduler] = None
_running_tasks = set()  # æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡IDï¼Œé˜²æ­¢å¹¶å‘æ‰§è¡Œ
_scheduler_lock_file = None  # è°ƒåº¦å™¨æ–‡ä»¶é”
_bettercap_continuous_tasks = {}  # å­˜å‚¨æŒç»­è¿è¡Œçš„ Bettercap ä»»åŠ¡
_bettercap_task_logs = {}  # å­˜å‚¨ Bettercap ä»»åŠ¡çš„åŸå§‹æ—¥å¿—ï¼ˆtask_id -> list of log linesï¼‰
_bettercap_task_friendly_logs = {}  # å­˜å‚¨ Bettercap ä»»åŠ¡çš„å‹å¥½æ—¥å¿—ï¼Œç”¨äºå†å²è®°å½•ï¼ˆtask_id -> list of log linesï¼‰


def _log_system_event(event_type: str, message: str, details: str = None, severity: str = "info"):
    """è®°å½•ç³»ç»Ÿäº‹ä»¶æ—¥å¿—åˆ°æ•°æ®åº“"""
    try:
        with Session(engine) as session:
            repo = SystemEventLogRepository(session)
            repo.create(
                event_type=event_type,
                message=message,
                details=details,
                severity=severity
            )
            logger.info(f"System event logged: {event_type} - {message}")
    except Exception as e:
        logger.error(f"Failed to log system event: {e}")


def _cleanup_old_system_logs():
    """æ¸…ç†30å¤©å‰çš„ç³»ç»Ÿäº‹ä»¶æ—¥å¿—"""
    try:
        with Session(engine) as session:
            repo = SystemEventLogRepository(session)
            deleted_count = repo.cleanup_old_logs(days=30)
            logger.info(f"[System Log Cleanup] Deleted {deleted_count} old system logs")
            
            # è®°å½•æ¸…ç†æ“ä½œæœ¬èº«
            if deleted_count > 0:
                repo.create(
                    event_type="system_log_cleanup",
                    message=f"è‡ªåŠ¨æ¸…ç†äº†{deleted_count}æ¡30å¤©å‰çš„ç³»ç»Ÿæ—¥å¿—",
                    details=json.dumps({"deleted_count": deleted_count}),
                    severity="info"
                )
    except Exception as e:
        logger.error(f"[System Log Cleanup] Failed to cleanup old logs: {e}")


def validate_cron_expression(cron_expr: str) -> bool:
    """éªŒè¯cronè¡¨è¾¾å¼æ˜¯å¦æœ‰æ•ˆ"""
    try:
        croniter(cron_expr)
        return True
    except Exception:
        return False


def _add_bettercap_log(task_id: int, message: str, friendly_message: str = None, max_lines: int = 1000, add_timestamp: bool = True):
    """
    æ·»åŠ  Bettercap ä»»åŠ¡æ—¥å¿—
    
    Args:
        task_id: ä»»åŠ¡ID
        message: åŸå§‹æ—¥å¿—æ¶ˆæ¯
        friendly_message: å‹å¥½æ ¼å¼çš„æ—¥å¿—æ¶ˆæ¯ï¼ˆç”¨äºå†å²è®°å½•ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨message
        max_lines: æœ€å¤§æ—¥å¿—è¡Œæ•°
        add_timestamp: æ˜¯å¦æ·»åŠ æ—¶é—´æˆ³
    """
    if task_id not in _bettercap_task_logs:
        _bettercap_task_logs[task_id] = []
    if task_id not in _bettercap_task_friendly_logs:
        _bettercap_task_friendly_logs[task_id] = []
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # åŸå§‹æ—¥å¿—ï¼šæ ¹æ®å‚æ•°å†³å®šæ˜¯å¦æ·»åŠ æ—¶é—´æˆ³
    if add_timestamp:
        raw_log_line = f"[{timestamp}] {message}"
    else:
        raw_log_line = message
    
    _bettercap_task_logs[task_id].append(raw_log_line)
    
    # å‹å¥½æ—¥å¿—ï¼šå§‹ç»ˆæ·»åŠ æ—¶é—´æˆ³
    friendly_log_line = f"[{timestamp}] {friendly_message if friendly_message else message}"
    _bettercap_task_friendly_logs[task_id].append(friendly_log_line)
    
    # ä¿æŒæ—¥å¿—æ•°é‡åœ¨é™åˆ¶å†…
    if len(_bettercap_task_logs[task_id]) > max_lines:
        _bettercap_task_logs[task_id] = _bettercap_task_logs[task_id][-max_lines:]
    if len(_bettercap_task_friendly_logs[task_id]) > max_lines:
        _bettercap_task_friendly_logs[task_id] = _bettercap_task_friendly_logs[task_id][-max_lines:]


async def start_bettercap_continuous_monitoring(task_id: int, cidrs: list):
    """å¯åŠ¨ Bettercap æŒç»­ç›‘æ§ï¼ˆnet.recon/net.probe æŒç»­å¼€å¯ï¼‰ï¼Œæ”¯æŒè‡ªåŠ¨é‡å¯"""
    logger.info(f"Starting Bettercap continuous monitoring for task {task_id}")
    target_cidr = cidrs[0] if cidrs and len(cidrs) > 0 else "æœ¬åœ°ç½‘ç»œ"
    _add_bettercap_log(
        task_id, 
        f"[å¯åŠ¨] Bettercap æŒç»­ç›‘æ§ï¼Œç›®æ ‡ç½‘æ®µ: {target_cidr}",
        friendly_message=f"ğŸš€ å¯åŠ¨ Bettercap æŒç»­ç›‘æ§ï¼Œç›®æ ‡ç½‘æ®µ: {target_cidr}",
        add_timestamp=True
    )
    
    # åŠ è½½é…ç½®
    try:
        with Session(engine) as session:
            config_repo = AppConfigRepository(session)
            config = config_repo.get_by_key("bettercap_config")
            if not config:
                # é…ç½®ä¸å­˜åœ¨æ—¶è®°å½•é”™è¯¯å¹¶è¿”å›
                error_msg = "Bettercap é…ç½®ä¸å­˜åœ¨ï¼Œè¯·å…ˆåœ¨è®¾ç½®é¡µé¢é…ç½®"
                logger.error(f"Task {task_id}: {error_msg}")
                _add_bettercap_log(
                    task_id,
                    f"[é”™è¯¯] {error_msg}",
                    friendly_message=f"âŒ {error_msg}",
                    add_timestamp=True
                )
                return
            
            config_dict = json.loads(config.value)
            # æ˜¾ç¤ºæ‰«æå®ä¾‹URLï¼ˆç«¯å£8081ï¼‰
            scan_url = config_dict.get('scan_url', config_dict.get('url', 'http://127.0.0.1:8081'))
            _add_bettercap_log(
                task_id, 
                f"[é…ç½®] å·²åŠ è½½ Bettercap æ‰«æé…ç½®: {scan_url}",
                friendly_message=f"âš™ï¸ å·²åŠ è½½ Bettercap æ‰«æé…ç½®: {scan_url}",
                add_timestamp=True
            )
    except Exception as e:
        error_msg = f"åŠ è½½ Bettercap é…ç½®å¤±è´¥: {e}"
        logger.error(f"Task {task_id}: {error_msg}")
        _add_bettercap_log(
            task_id, 
            f"[é”™è¯¯] {error_msg}",
            friendly_message=f"âŒ é”™è¯¯: {error_msg}",
            add_timestamp=True
        )
        return
    
    retry_count = 0
    max_retries = 10  # æœ€å¤§é‡è¯•æ¬¡æ•°
    retry_delay = 10  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    
    # è‡ªåŠ¨é‡å¯å¾ªç¯
    while task_id in _bettercap_continuous_tasks and retry_count < max_retries:
        try:
            # ä½¿ç”¨å•ä¾‹ç®¡ç†å™¨è·å–å®¢æˆ·ç«¯
            _add_bettercap_log(
                task_id,
                f"[å®¢æˆ·ç«¯] è·å–Bettercapå®¢æˆ·ç«¯å®ä¾‹...",
                friendly_message="âš™ï¸ è·å–Bettercapå®¢æˆ·ç«¯å®ä¾‹...",
                add_timestamp=True
            )
            client = await BettercapClientManager.get_client()
            _add_bettercap_log(
                task_id,
                f"[å®¢æˆ·ç«¯] å®¢æˆ·ç«¯å®ä¾‹è·å–æˆåŠŸ",
                friendly_message="âœ“ å®¢æˆ·ç«¯å®ä¾‹è·å–æˆåŠŸ",
                add_timestamp=True
            )
        except Exception as e:
            error_msg = f"è·å–Bettercapå®¢æˆ·ç«¯å¤±è´¥: {e}"
            logger.error(f"Task {task_id}: {error_msg}")
            _add_bettercap_log(
                task_id,
                f"[é”™è¯¯] {error_msg}",
                friendly_message=f"âŒ é”™è¯¯: {error_msg}",
                add_timestamp=True
            )
            retry_count += 1
            if retry_count < max_retries:
                await asyncio.sleep(retry_delay)
                continue
            else:
                break
        
        try:
            # å¯åŠ¨ net.recon å’Œ net.probe
            if retry_count > 0:
                _add_bettercap_log(
                    task_id, 
                    f"[é‡è¯•] ç¬¬ {retry_count} æ¬¡é‡å¯å°è¯•...",
                    friendly_message=f"ğŸ”„ ç¬¬ {retry_count} æ¬¡é‡å¯å°è¯•...",
                    add_timestamp=True
                )
                # è®°å½•ç³»ç»Ÿäº‹ä»¶æ—¥å¿—
                _log_system_event(
                    event_type="bettercap_restart",
                    message=f"Bettercapæ‰«æå®ä¾‹è‡ªåŠ¨é‡å¯ï¼ˆä»»åŠ¡ID: {task_id}, ç¬¬{retry_count}æ¬¡é‡è¯•ï¼‰",
                    details=json.dumps({"task_id": task_id, "retry_count": retry_count, "target_cidr": target_cidr}),
                    severity="warning"
                )
            
            # æ¸…ç©ºä¹‹å‰çš„ä¸»æœºç¼“å­˜
            result = await client.execute_command("net.clear")
            
            # é…ç½®æ‰«æç›®æ ‡ç½‘æ®µï¼ˆå¦‚æœæŒ‡å®šäº† CIDRï¼‰
            if cidrs and len(cidrs) > 0:
                # Bettercap ä½¿ç”¨å•ä¸ªç½‘æ®µ
                target = cidrs[0]
                result = await client.execute_command(f"set net.recon.targets {target}")
                _add_bettercap_log(
                    task_id, 
                    f"[é…ç½®] è®¾ç½®æ‰«æç›®æ ‡: {target}",
                    friendly_message=f"ğŸ¯ è®¾ç½®æ‰«æç›®æ ‡: {target}",
                    add_timestamp=True
                )
                logger.info(f"Task {task_id}: Set bettercap targets to {target}")
            
            # è·å–æ¢æµ‹æ¨¡å¼é…ç½®
            probe_mode = config_dict.get('probe_mode', 'active')
            probe_throttle = config_dict.get('probe_throttle', 5)
            
            # æ ¹æ®æ¢æµ‹æ¨¡å¼é…ç½®å’Œå¯åŠ¨æ¨¡å—
            if probe_mode == 'active':
                # ä¸»åŠ¨æ¢æµ‹æ¨¡å¼ï¼šå…ˆå¯åŠ¨net.reconï¼Œå†å¯åŠ¨net.probe
                await client.execute_command(f"set net.probe.throttle {probe_throttle}")
                await client.execute_command("set net.probe.mdns true")
                await client.execute_command("set net.probe.timeout 3")
                
                _add_bettercap_log(
                    task_id, 
                    f"[é…ç½®] ä¸»åŠ¨æ¢æµ‹æ¨¡å¼: é—´éš”{probe_throttle}ç§’, è¶…æ—¶3ç§’, mDNSå¯ç”¨",
                    friendly_message=f"âš¡ ä¸»åŠ¨æ¢æµ‹æ¨¡å¼: é—´éš”{probe_throttle}ç§’ï¼ˆå¿«é€Ÿæ£€æµ‹è®¾å¤‡ä¸Šä¸‹çº¿ï¼‰",
                    add_timestamp=True
                )
                
                # å…ˆå¯åŠ¨net.reconï¼ˆè¢«åŠ¨ä¾¦å¯Ÿï¼‰
                await client.execute_command("net.recon on")
                logger.info(f"Task {task_id}: Bettercap net.recon started")
                
                # å†å¯åŠ¨net.probeï¼ˆä¸»åŠ¨æ¢æµ‹ï¼‰
                await client.execute_command("net.probe on")
                logger.info(f"Task {task_id}: Bettercap net.probe started (active mode)")
                
                # è®°å½•åˆ°ç³»ç»Ÿäº‹ä»¶æ—¥å¿—
                _log_system_event(
                    event_type="bettercap_modules_started",
                    message=f"Bettercapæ‰«ææ¨¡å—å·²å¯åŠ¨ï¼ˆä»»åŠ¡ID: {task_id}ï¼‰",
                    details=json.dumps({
                        "task_id": task_id,
                        "mode": "active",
                        "modules": ["net.recon", "net.probe"],
                        "target_cidr": target_cidr,
                        "probe_throttle": probe_throttle
                    }),
                    severity="info"
                )
                
            else:  # passive
                # è¢«åŠ¨ä¾¦å¯Ÿæ¨¡å¼
                _add_bettercap_log(
                    task_id, 
                    "[é…ç½®] è¢«åŠ¨ä¾¦å¯Ÿæ¨¡å¼: ç›‘å¬ç½‘ç»œæµé‡",
                    friendly_message="ğŸ‘ï¸ è¢«åŠ¨ä¾¦å¯Ÿæ¨¡å¼: å®Œå…¨éšè”½ï¼Œé€šè¿‡æµé‡å‘ç°è®¾å¤‡",
                    add_timestamp=True
                )
                
                await client.execute_command("net.recon on")
                logger.info(f"Task {task_id}: Bettercap passive recon started")
                
                # è®°å½•åˆ°ç³»ç»Ÿäº‹ä»¶æ—¥å¿—
                _log_system_event(
                    event_type="bettercap_modules_started",
                    message=f"Bettercapæ‰«ææ¨¡å—å·²å¯åŠ¨ï¼ˆä»»åŠ¡ID: {task_id}ï¼‰",
                    details=json.dumps({
                        "task_id": task_id,
                        "mode": "passive",
                        "modules": ["net.recon"],
                        "target_cidr": target_cidr
                    }),
                    severity="info"
                )
            
            _add_bettercap_log(
                task_id, 
                f"[å¯åŠ¨å®Œæˆ] Bettercap {probe_mode} æ¨¡å¼å·²å¯åŠ¨",
                friendly_message=f"âœ“ Bettercap å·²å¯åŠ¨ï¼Œå¼€å§‹æŒç»­ç›‘æ§ï¼ˆ{probe_mode} æ¨¡å¼ï¼‰",
                add_timestamp=True
            )
            
            # é‡ç½®é‡è¯•è®¡æ•°ï¼ˆå¯åŠ¨æˆåŠŸï¼‰
            retry_count = 0
            last_event_time = datetime.now()
            
            # æŒç»­æ‹‰å–å¹¶æ˜¾ç¤º Bettercap åŸå§‹äº‹ä»¶æ—¥å¿—
            last_event_id = None
            poll_interval = 2  # æ¯2ç§’æ‹‰å–ä¸€æ¬¡äº‹ä»¶
            
            while task_id in _bettercap_continuous_tasks:
                try:
                    # è·å–æœ€æ–°çš„ Bettercap äº‹ä»¶
                    try:
                        events = await client.get_events(limit=100)
                        if events:
                            # è¿‡æ»¤å‡ºæ–°äº‹ä»¶ï¼ˆé¿å…é‡å¤æ˜¾ç¤ºï¼‰
                            new_events = []
                            for event in reversed(events):  # ä»æ—§åˆ°æ–°æ’åº
                                event_id = event.get('id')
                                if last_event_id is None or (event_id and event_id > last_event_id):
                                    new_events.append(event)
                                    if event_id:
                                        last_event_id = max(last_event_id or 0, event_id)
                            
                            # æ˜¾ç¤ºæ‰€æœ‰æ–°äº‹ä»¶ï¼ˆåŸå§‹æ ¼å¼ï¼‰
                            for event in new_events:
                                # è·å–äº‹ä»¶ä¿¡æ¯
                                tag = event.get('tag', '')
                                time_str = event.get('time', '')
                                
                                # æ ¼å¼åŒ–æ—¶é—´ï¼ˆåªæ˜¾ç¤ºæ—¶:åˆ†:ç§’ï¼‰
                                if 'T' in time_str:
                                    time_display = time_str.split('T')[1].split('.')[0] if 'T' in time_str else time_str
                                else:
                                    time_display = time_str
                                
                                # è·å–äº‹ä»¶æ•°æ®
                                data = event.get('data', {})
                                
                                # æ ¹æ®äº‹ä»¶ç±»å‹æ ¼å¼åŒ–è¾“å‡ºï¼ˆæ¨¡æ‹Ÿ bettercap åŸå§‹è¾“å‡ºï¼‰
                                if tag == 'endpoint.new':
                                    endpoint = data.get('endpoint', {})
                                    ip = endpoint.get('ipv4', '')
                                    mac = endpoint.get('mac', '')
                                    hostname = endpoint.get('hostname', '')
                                    vendor = endpoint.get('vendor', '')
                                    
                                    # æ„å»ºç±»ä¼¼ bettercap åŸå§‹è¾“å‡ºçš„æ ¼å¼
                                    raw_output = f"[{time_display}] [sys.log] [inf] endpoint.new {ip}"
                                    if mac:
                                        raw_output += f" {mac}"
                                    if hostname:
                                        raw_output += f" {hostname}"
                                    if vendor:
                                        raw_output += f" ({vendor})"
                                    
                                    # æ„å»ºå‹å¥½æ ¼å¼
                                    device_name = hostname or vendor or mac[:17] if mac else ip
                                    friendly_output = f"ğŸŸ¢ è®¾å¤‡ä¸Šçº¿: {ip} ({device_name})"
                                    
                                    _add_bettercap_log(task_id, raw_output, friendly_message=friendly_output, add_timestamp=False)
                                    
                                    # ç«‹å³åœ¨æ•°æ®åº“ä¸­æ›´æ–°è¯¥è®¾å¤‡ä¸ºåœ¨çº¿
                                    if ip and (mac or hostname):
                                        try:
                                            with Session(engine) as db_session:
                                                from app.repositories.device_repo import DeviceRepository
                                                from app.models.device import Device
                                                device_repo = DeviceRepository(db_session)
                                                device = device_repo.get_by_ip(ip)
                                                if device:
                                                    # æ›´æ–°ç°æœ‰è®¾å¤‡
                                                    device.lastSeenAt = datetime.now()
                                                    device.bettercap_last_seen = datetime.now()
                                                    device.bettercap_offline_at = None
                                                    device.offline_at = None
                                                    if mac:
                                                        device.mac = mac
                                                    if hostname:
                                                        device.hostname = hostname
                                                    if vendor:
                                                        device.vendor = vendor
                                                    device_repo.update(device)
                                                else:
                                                    # åˆ›å»ºæ–°è®¾å¤‡
                                                    now = datetime.now()
                                                    device = Device(
                                                        ip=ip,
                                                        mac=mac,
                                                        hostname=hostname,
                                                        vendor=vendor,
                                                        firstSeenAt=now,
                                                        lastSeenAt=now,
                                                        bettercap_last_seen=now
                                                    )
                                                    device_repo.create(device)
                                                logger.info(f"Task {task_id}: Updated/created device {ip} as online immediately")
                                        except Exception as e:
                                            logger.error(f"Task {task_id}: Failed to update device {ip} online: {e}")
                                    
                                elif tag == 'endpoint.lost':
                                    endpoint = data.get('endpoint', {})
                                    ip = endpoint.get('ipv4', '')
                                    mac = endpoint.get('mac', '')
                                    hostname = endpoint.get('hostname', '')
                                    vendor = endpoint.get('vendor', '')
                                    
                                    raw_output = f"[{time_display}] [sys.log] [inf] endpoint.lost {ip}"
                                    if mac:
                                        raw_output += f" {mac}"
                                    
                                    # æ„å»ºå‹å¥½æ ¼å¼
                                    device_name = hostname or vendor or mac[:17] if mac else ip
                                    friendly_output = f"ğŸ”´ è®¾å¤‡ç¦»çº¿: {ip} ({device_name})"
                                    
                                    _add_bettercap_log(task_id, raw_output, friendly_message=friendly_output, add_timestamp=False)
                                    
                                    # ç«‹å³åœ¨æ•°æ®åº“ä¸­æ ‡è®°è¯¥è®¾å¤‡ä¸ºç¦»çº¿
                                    if ip:
                                        try:
                                            with Session(engine) as db_session:
                                                from app.repositories.device_repo import DeviceRepository
                                                device_repo = DeviceRepository(db_session)
                                                device = device_repo.get_by_ip(ip)
                                                if device:
                                                    device.bettercap_offline_at = datetime.now()
                                                    device.offline_at = datetime.now()  # å…¼å®¹æ—§å­—æ®µ
                                                    device_repo.update(device)
                                                    logger.info(f"Task {task_id}: Marked device {ip} as offline immediately")
                                        except Exception as e:
                                            logger.error(f"Task {task_id}: Failed to mark device {ip} offline: {e}")
                                    
                                elif tag.startswith('wifi.') or tag.startswith('ble.') or tag.startswith('hid.'):
                                    # æ— çº¿ç›¸å…³äº‹ä»¶
                                    raw_output = f"[{time_display}] [sys.log] [inf] {tag} {json.dumps(data)}"
                                    friendly_output = f"ğŸ“¡ {tag}"
                                    _add_bettercap_log(task_id, raw_output, friendly_message=friendly_output, add_timestamp=False)
                                    
                                elif tag == 'sys.log':
                                    # ç³»ç»Ÿæ—¥å¿—
                                    message = data.get('Message', '')
                                    level = data.get('Level', 'inf')
                                    raw_output = f"[{time_display}] [sys.log] [{level}] {message}"
                                    friendly_output = f"â„¹ï¸ {message}"
                                    _add_bettercap_log(task_id, raw_output, friendly_message=friendly_output, add_timestamp=False)
                                    
                                else:
                                    # å…¶ä»–äº‹ä»¶ï¼Œæ˜¾ç¤ºåŸå§‹ JSON
                                    raw_output = f"[{time_display}] [{tag}] {json.dumps(data)}"
                                    friendly_output = f"ğŸ“‹ {tag}"
                                    _add_bettercap_log(task_id, raw_output, friendly_message=friendly_output, add_timestamp=False)
                                    
                    except Exception as e:
                        logger.debug(f"Task {task_id}: Failed to get events: {e}")
                    
                    # æ¯60ç§’æ›´æ–°ä¸€æ¬¡ä¸»æœºåˆ—è¡¨åˆ°æ•°æ®åº“
                    if (datetime.now() - last_event_time).total_seconds() > 60:
                        # è·å–ä¸»æœºåˆ—è¡¨
                        hosts_list = await client.get_lan_hosts()
                        logger.debug(f"Task {task_id}: Bettercap found {len(hosts_list)} hosts")
                        
                        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                        from app.services.bettercap_service import convert_bettercap_host_to_device_info
                        hosts_dict = {}
                        for host in hosts_list:
                            ip = host.get("ipv4")
                            if ip:
                                hosts_dict[ip] = convert_bettercap_host_to_device_info(host)
                        
                        # æ›´æ–°è®¾å¤‡è®°å½•
                        with Session(engine) as session:
                            updated, new_count, offline_count = upsert_devices_with_info(
                                session, 
                                hosts_dict,
                                mark_offline=True,
                                target_cidrs=cidrs,
                                scan_tool="bettercap"  # Bettercap æ‰«æ
                            )
                            logger.info(f"Task {task_id}: Updated {updated} devices, {new_count} new, {offline_count} offline")
                            _add_bettercap_log(
                                task_id, 
                                f"[DBæ›´æ–°] å‘ç° {len(hosts_dict)} å°ä¸»æœºï¼Œæ›´æ–° {updated} æ¡è®°å½•ï¼ˆæ–°å¢ {new_count}ï¼Œç¦»çº¿ {offline_count}ï¼‰",
                                friendly_message=f"âœ“ å‘ç° {len(hosts_dict)} å°ä¸»æœºï¼Œæ›´æ–° {updated} æ¡è®°å½•ï¼ˆæ–°å¢ {new_count}ï¼Œç¦»çº¿ {offline_count}ï¼‰",
                                add_timestamp=True
                            )
                        last_event_time = datetime.now()
                    
                    await asyncio.sleep(poll_interval)  # æŒ‰äº‹ä»¶è½®è¯¢é—´éš”ä¼‘çœ 
                    
                except asyncio.CancelledError:
                    logger.info(f"Task {task_id}: Bettercap monitoring cancelled")
                    _add_bettercap_log(
                        task_id, 
                        "[åœæ­¢] ç›‘æ§å·²åœæ­¢",
                        friendly_message="âœ“ ç›‘æ§å·²åœæ­¢",
                        add_timestamp=True
                    )
                    raise  # é‡æ–°æŠ›å‡ºä»¥é€€å‡ºå¤–å±‚å¾ªç¯
                except Exception as e:
                    logger.error(f"Task {task_id}: Bettercap monitoring error: {e}")
                    _add_bettercap_log(
                        task_id, 
                        f"[è­¦å‘Š] ç›‘æ§å¾ªç¯é”™è¯¯: {e}",
                        friendly_message=f"âš  ç›‘æ§å¾ªç¯é”™è¯¯: {e}",
                        add_timestamp=True
                    )
                    # å°é”™è¯¯ç»§ç»­è¿è¡Œ
                    await asyncio.sleep(60)
                    
        except asyncio.CancelledError:
            # ä»»åŠ¡è¢«å–æ¶ˆï¼Œæ­£å¸¸é€€å‡º
            break
        except Exception as e:
            error_msg = f"Bettercap ç›‘æ§å¼‚å¸¸: {e}"
            logger.error(f"Task {task_id}: {error_msg}")
            _add_bettercap_log(
                task_id, 
                f"[é”™è¯¯] {error_msg}",
                friendly_message=f"âŒ é”™è¯¯: {error_msg}",
                add_timestamp=True
            )
            
            retry_count += 1
            if retry_count < max_retries and task_id in _bettercap_continuous_tasks:
                _add_bettercap_log(
                    task_id, 
                    f"[é‡è¯•] {retry_delay} ç§’åè‡ªåŠ¨é‡å¯...",
                    friendly_message=f"â³ {retry_delay} ç§’åè‡ªåŠ¨é‡å¯...",
                    add_timestamp=True
                )
                await asyncio.sleep(retry_delay)
            else:
                _add_bettercap_log(
                    task_id, 
                    f"[é”™è¯¯] å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ï¼Œåœæ­¢ç›‘æ§",
                    friendly_message=f"âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ï¼Œåœæ­¢ç›‘æ§",
                    add_timestamp=True
                )
                break
        finally:
            # åœæ­¢ Bettercap æ¨¡å—ï¼ˆå®‰å…¨åœæ­¢æ‰€æœ‰å¯èƒ½å¯åŠ¨çš„æ¨¡å—ï¼‰
            try:
                # å°è¯•åœæ­¢ä¸»åŠ¨æ¢æµ‹
                try:
                    await client.execute_command("net.probe off")
                    logger.debug(f"Task {task_id}: net.probe stopped")
                except Exception:
                    pass
                
                # å°è¯•åœæ­¢è¢«åŠ¨ä¾¦å¯Ÿ
                try:
                    await client.execute_command("net.recon off")
                    logger.debug(f"Task {task_id}: net.recon stopped")
                except Exception:
                    pass
                
                logger.info(f"Task {task_id}: Bettercap modules stopped")
                _add_bettercap_log(
                    task_id, 
                    "[åœæ­¢] Bettercap æ¨¡å—å·²åœæ­¢",
                    friendly_message="âœ“ Bettercap å·²åœæ­¢",
                    add_timestamp=True
                )
            except Exception as e:
                logger.error(f"Task {task_id}: Failed to stop Bettercap modules: {e}")
                _add_bettercap_log(
                    task_id, 
                    f"[è­¦å‘Š] åœæ­¢æ¨¡å—æ—¶å‡ºé”™: {e}",
                    friendly_message=f"âš  åœæ­¢æ¨¡å—æ—¶å‡ºé”™: {e}",
                    add_timestamp=True
                )


def stop_bettercap_continuous_monitoring(task_id: int):
    """åœæ­¢ Bettercap æŒç»­ç›‘æ§"""
    if task_id in _bettercap_continuous_tasks:
        task = _bettercap_continuous_tasks[task_id]
        task.cancel()
        del _bettercap_continuous_tasks[task_id]
        logger.info(f"Stopped Bettercap continuous monitoring for task {task_id}")


def get_bettercap_task_logs(task_id: int, log_type: str = "raw") -> list:
    """
    è·å– Bettercap ä»»åŠ¡çš„æ—¥å¿—
    
    Args:
        task_id: ä»»åŠ¡ID
        log_type: æ—¥å¿—ç±»å‹ï¼Œ"raw" ä¸ºåŸå§‹æ—¥å¿—ï¼ˆå®æ—¶æŸ¥çœ‹ï¼‰ï¼Œ"friendly" ä¸ºå‹å¥½æ—¥å¿—ï¼ˆå†å²è®°å½•ï¼‰
    
    Returns:
        æ—¥å¿—åˆ—è¡¨
    """
    if log_type == "friendly":
        return _bettercap_task_friendly_logs.get(task_id, [])
    else:
        return _bettercap_task_logs.get(task_id, [])


async def execute_scheduled_task(task_id: int):
    """æ‰§è¡Œå®šæ—¶æ‰«æä»»åŠ¡"""
    logger.info("=" * 60)
    logger.info(f"TASK EXECUTION TRIGGERED: Task ID {task_id}")
    logger.info(f"Time: {datetime.now().isoformat()}")
    
    # é˜²æ­¢åŒä¸€ä»»åŠ¡å¹¶å‘æ‰§è¡Œ
    if task_id in _running_tasks:
        logger.warning(f"Task {task_id} is already running, skipping")
        logger.info("=" * 60)
        return
    
    _running_tasks.add(task_id)
    logger.info(f"Added task {task_id} to running tasks. Current running: {_running_tasks}")
    
    try:
        # æ¯æ¬¡æ‰§è¡Œæ—¶åˆ›å»ºæ–°çš„Sessionï¼Œé¿å…çº¿ç¨‹å†²çª
        session = Session(engine, expire_on_commit=False)
        try:
            # è·å–ä»»åŠ¡ä¿¡æ¯
            task_repo = ScheduledTaskRepository(session)
            task = task_repo.get_by_id(task_id)
            
            if not task:
                logger.error(f"Task {task_id} not found in database")
                return
            
            if not task.enabled:
                logger.warning(f"Task {task_id} is disabled, skipping execution")
                return
            
            # å¦‚æœæ˜¯ Bettercap ä»»åŠ¡ï¼Œä¸åœ¨è¿™é‡Œæ‰§è¡Œï¼ˆç”±æŒç»­ç›‘æ§å¤„ç†ï¼‰
            if task.scan_tool == "bettercap":
                logger.info(f"Task {task_id} uses Bettercap continuous mode, skipping cron execution")
                return
            
            logger.info(f"Task details: {task.name}")
            logger.info(f"  CIDRs: {task.cidrs}")
            logger.info(f"  Scan tool: {task.scan_tool}")
            logger.info(f"  Nmap args: {task.nmap_args or 'default'}")
            logger.info(f"  Cron: {task.cron_expression}")
            
            # åˆ›å»ºæ‰§è¡Œè®°å½•
            exec_repo = TaskExecutionRepository(session)
            execution = TaskExecution(
                task_id=task_id,
                started_at=datetime.now(),
                status="running"
            )
            execution = exec_repo.create(execution)
            
            try:
                # è§£æç½‘æ®µåˆ—è¡¨
                cidrs = json.loads(task.cidrs)
                logger.info(f"Starting scan for {len(cidrs)} CIDR(s): {cidrs}")
                
                # æ‰§è¡Œæ‰«æ
                logger.info(f"Executing nmap scan...")
                devices_info, raw_output = await scan_nmap(cidrs, task.nmap_args)
                logger.info(f"Scan completed, found {len(devices_info)} online devices")
                
                # æ›´æ–°è®¾å¤‡è®°å½•å¹¶æ ‡è®°ç¦»çº¿è®¾å¤‡
                logger.info(f"Updating device records...")
                updated, new_count, offline_count = upsert_devices_with_info(
                    session, 
                    devices_info,
                    mark_offline=True,
                    target_cidrs=cidrs,
                    scan_tool="nmap"  # Nmap æ‰«æ
                )
                logger.info(f"Device records updated: {updated} total, {new_count} new, {offline_count} offline")
                
                # æ›´æ–°æ‰§è¡Œè®°å½•
                execution.completed_at = datetime.now()
                execution.status = "success"
                execution.online_count = len(devices_info)
                execution.offline_count = offline_count
                execution.new_count = new_count
                execution.raw_output = raw_output  # ä¿å­˜NmapåŸå§‹è¾“å‡º
                exec_repo.update(execution)
                
                # æ›´æ–°ä»»åŠ¡çš„æœ€åæ‰§è¡Œæ—¶é—´
                task.last_run_at = datetime.now()
                task_repo.update(task)
                
                # æäº¤æ‰€æœ‰æ›´æ”¹
                session.commit()
                
                logger.info(f"âœ“ Task {task_id} completed successfully")
                logger.info(f"  Online: {len(devices_info)}, Offline: {offline_count}, New: {new_count}")
                logger.info("=" * 60)
                
            except Exception as e:
                # è®°å½•é”™è¯¯
                logger.error(f"âœ— Task {task_id} failed with error: {str(e)}", exc_info=True)
                execution.completed_at = datetime.now()
                execution.status = "failed"
                execution.error_message = str(e)
                exec_repo.update(execution)
                session.commit()
                logger.info("=" * 60)
        
        finally:
            session.close()
                
    finally:
        _running_tasks.discard(task_id)


def _execute_task_wrapper(task_id: int):
    """ä»»åŠ¡æ‰§è¡ŒåŒ…è£…å™¨ï¼Œåœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ"""
    # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        loop.run_until_complete(execute_scheduled_task(task_id))
    finally:
        loop.close()


def _schedule_task(task: ScheduledTask):
    """å°†ä»»åŠ¡æ·»åŠ åˆ°è°ƒåº¦å™¨"""
    if not _scheduler:
        return
    
    job_id = f"task_{task.id}"
    
    # å¦‚æœæ˜¯ Bettercap ä»»åŠ¡ï¼Œå¯åŠ¨æŒç»­ç›‘æ§
    if task.scan_tool == "bettercap":
        # åœæ­¢å¯èƒ½å·²å­˜åœ¨çš„ç›‘æ§
        stop_bettercap_continuous_monitoring(task.id)
        
        # å¯åŠ¨æ–°çš„æŒç»­ç›‘æ§
        try:
            cidrs = json.loads(task.cidrs)
            loop = asyncio.get_event_loop()
            continuous_task = loop.create_task(
                start_bettercap_continuous_monitoring(task.id, cidrs)
            )
            _bettercap_continuous_tasks[task.id] = continuous_task
            logger.info(f"Started Bettercap continuous monitoring for task {task.id}: {task.name}")
        except Exception as e:
            logger.error(f"Failed to start Bettercap monitoring for task {task.id}: {e}")
    else:
        # Nmap ä»»åŠ¡ï¼šä½¿ç”¨ cron è°ƒåº¦
        # ç§»é™¤å·²å­˜åœ¨çš„ä»»åŠ¡
        if _scheduler.get_job(job_id):
            _scheduler.remove_job(job_id)
        
        # æ·»åŠ æ–°ä»»åŠ¡
        trigger = CronTrigger.from_crontab(task.cron_expression)
        _scheduler.add_job(
            func=_execute_task_wrapper,
            args=[task.id],
            trigger=trigger,
            id=job_id,
            name=task.name,
            replace_existing=True
        )
        logger.info(f"Scheduled task {task.id}: {task.name} with cron {task.cron_expression}")


def start_scheduler():
    """å¯åŠ¨è°ƒåº¦å™¨å¹¶åŠ è½½æ‰€æœ‰å¯ç”¨çš„ä»»åŠ¡"""
    global _scheduler, _scheduler_lock_file
    
    if _scheduler is not None:
        logger.warning("Scheduler already started in this process")
        return
    
    # å°è¯•è·å–æ–‡ä»¶é”ï¼Œç¡®ä¿åªæœ‰ä¸€ä¸ªè¿›ç¨‹å¯åŠ¨è°ƒåº¦å™¨
    lock_file_path = '/tmp/niar_scheduler.lock'
    
    try:
        _scheduler_lock_file = open(lock_file_path, 'w')
        fcntl.flock(_scheduler_lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
        logger.info("=" * 60)
        logger.info("âœ“ Acquired scheduler lock, this process will run the scheduler")
        logger.info(f"Process ID: {os.getpid()}")
    except BlockingIOError:
        logger.info("=" * 60)
        logger.info("âœ— Another process already has the scheduler lock")
        logger.info(f"Process ID: {os.getpid()}")
        logger.info("This process will NOT start a scheduler (to avoid conflicts)")
        logger.info("=" * 60)
        return
    except Exception as e:
        logger.error(f"Failed to acquire scheduler lock: {str(e)}")
        return
    
    logger.info("Starting APScheduler...")
    # ä½¿ç”¨æœ¬åœ°æ—¶åŒºè€Œä¸æ˜¯UTC
    from tzlocal import get_localzone
    local_tz = get_localzone()
    logger.info(f"Using timezone: {local_tz}")
    _scheduler = BackgroundScheduler(timezone=local_tz)
    _scheduler.start()
    logger.info(f"Scheduler started successfully. Running: {_scheduler.running}")
    
    # åŠ è½½æ‰€æœ‰å¯ç”¨çš„ä»»åŠ¡
    with Session(engine) as session:
        task_repo = ScheduledTaskRepository(session)
        enabled_tasks = task_repo.get_enabled()
        
        logger.info(f"Found {len(enabled_tasks)} enabled tasks in database")
        
        for task in enabled_tasks:
            try:
                _schedule_task(task)
                logger.info(f"  âœ“ Scheduled: {task.name} (ID: {task.id}, Cron: {task.cron_expression})")
            except Exception as e:
                logger.error(f"  âœ— Failed to schedule task {task.id}: {str(e)}")
    
    # æ·»åŠ ç³»ç»Ÿæ—¥å¿—æ¸…ç†ä»»åŠ¡ï¼ˆæ¯å¤©å‡Œæ™¨3ç‚¹æ‰§è¡Œï¼‰
    _scheduler.add_job(
        func=_cleanup_old_system_logs,
        trigger='cron',
        hour=3,
        minute=0,
        id='cleanup_system_logs',
        name='æ¸…ç†30å¤©å‰çš„ç³»ç»Ÿæ—¥å¿—',
        replace_existing=True
    )
    logger.info("  âœ“ Scheduled: ç³»ç»Ÿæ—¥å¿—æ¸…ç†ä»»åŠ¡ (æ¯å¤© 03:00)")
    
    # æ˜¾ç¤ºæ‰€æœ‰å·²åŠ è½½çš„ä»»åŠ¡
    jobs = _scheduler.get_jobs()
    logger.info(f"Total jobs in scheduler: {len(jobs)}")
    for job in jobs:
        logger.info(f"  - Job: {job.id}, Next run: {job.next_run_time}")
    logger.info("=" * 60)


def stop_scheduler():
    """åœæ­¢è°ƒåº¦å™¨"""
    global _scheduler, _scheduler_lock_file
    
    if _scheduler:
        _scheduler.shutdown(wait=False)
        _scheduler = None
        logger.info("Scheduler stopped")
    
    # é‡Šæ”¾æ–‡ä»¶é”
    if _scheduler_lock_file:
        try:
            fcntl.flock(_scheduler_lock_file.fileno(), fcntl.LOCK_UN)
            _scheduler_lock_file.close()
            _scheduler_lock_file = None
            logger.info("Scheduler lock released")
        except Exception as e:
            logger.error(f"Failed to release scheduler lock: {str(e)}")


def reload_task(task_id: int):
    """é‡æ–°åŠ è½½æŒ‡å®šä»»åŠ¡"""
    with Session(engine) as session:
        task_repo = ScheduledTaskRepository(session)
        task = task_repo.get_by_id(task_id)
        
        if not task:
            return
        
        job_id = f"task_{task_id}"
        
        # åœæ­¢ Bettercap æŒç»­ç›‘æ§ï¼ˆå¦‚æœæœ‰ï¼‰
        stop_bettercap_continuous_monitoring(task_id)
        
        # ç§»é™¤ cron ä»»åŠ¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if _scheduler and _scheduler.get_job(job_id):
            _scheduler.remove_job(job_id)
        
        # å¦‚æœä»»åŠ¡å·²å¯ç”¨ï¼Œé‡æ–°æ·»åŠ 
        if task.enabled:
            _schedule_task(task)
        else:
            logger.info(f"Task {task_id} is disabled, not scheduling")


def remove_task(task_id: int):
    """ä»è°ƒåº¦å™¨ä¸­ç§»é™¤ä»»åŠ¡"""
    # åœæ­¢ Bettercap æŒç»­ç›‘æ§
    stop_bettercap_continuous_monitoring(task_id)
    
    # ç§»é™¤ cron ä»»åŠ¡
    if _scheduler:
        job_id = f"task_{task_id}"
        if _scheduler.get_job(job_id):
            _scheduler.remove_job(job_id)
            logger.info(f"Removed task {task_id} from scheduler")


def get_scheduler_status() -> dict:
    """è·å–è°ƒåº¦å™¨çŠ¶æ€"""
    # æ£€æŸ¥é”æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œåˆ¤æ–­æ˜¯å¦æœ‰è¿›ç¨‹æŒæœ‰è°ƒåº¦å™¨
    lock_file_path = '/tmp/niar_scheduler.lock'
    scheduler_running = False
    
    # å°è¯•æ£€æŸ¥é”æ–‡ä»¶
    if os.path.exists(lock_file_path):
        try:
            # å°è¯•è·å–éé˜»å¡é”æ¥æµ‹è¯•
            test_lock = open(lock_file_path, 'r')
            fcntl.flock(test_lock.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
            # å¦‚æœæˆåŠŸè·å–ï¼Œè¯´æ˜æ²¡æœ‰å…¶ä»–è¿›ç¨‹æŒæœ‰ â†’ è°ƒåº¦å™¨å¯èƒ½å·²åœæ­¢
            fcntl.flock(test_lock.fileno(), fcntl.LOCK_UN)
            test_lock.close()
            scheduler_running = False
        except BlockingIOError:
            # æ— æ³•è·å–é”ï¼Œè¯´æ˜æœ‰å…¶ä»–è¿›ç¨‹æŒæœ‰ â†’ è°ƒåº¦å™¨æ­£åœ¨è¿è¡Œ
            scheduler_running = True
        except Exception:
            scheduler_running = False
    
    # å¦‚æœæœ¬è¿›ç¨‹æœ‰è°ƒåº¦å™¨ï¼Œè¿”å›è¯¦ç»†ä¿¡æ¯
    if _scheduler and _scheduler.running:
        jobs = _scheduler.get_jobs()
        job_details = [
            {
                "id": job.id,
                "name": job.name,
                "next_run_time": job.next_run_time.isoformat() if job.next_run_time else None,
                "trigger": str(job.trigger)
            }
            for job in jobs
        ]
        
        return {
            "running": True,
            "jobs": len(jobs),
            "job_details": job_details,
            "running_tasks": list(_running_tasks),
            "bettercap_tasks": list(_bettercap_continuous_tasks.keys()),
            "this_process_has_scheduler": True
        }
    
    # æœ¬è¿›ç¨‹æ²¡æœ‰è°ƒåº¦å™¨ï¼Œä½†é€šè¿‡é”æ–‡ä»¶åˆ¤æ–­æ•´ä½“çŠ¶æ€
    return {
        "running": scheduler_running,
        "jobs": 0,  # æœ¬è¿›ç¨‹ä¸çŸ¥é“å…·ä½“ä»»åŠ¡æ•°
        "job_details": [],
        "running_tasks": [],
        "this_process_has_scheduler": False,
        "note": "Scheduler is running in another process" if scheduler_running else "Scheduler is not running"
    }

